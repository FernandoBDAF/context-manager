# PLAN: Graph Construction Refactor & Quality Enhancement

**Status**: Planning  
**Created**: 2025-11-06 22:30 UTC  
**Goal**: Fix critical bugs in graph construction, improve graph modeling correctness, optimize performance, and establish quality metrics  
**Priority**: HIGH - Foundational for community detection and trust scoring

---

## üìñ Context for LLM Execution

**If you're an LLM reading this to execute work**:

1. **What This Plan Is**: Refactor graph construction stage to fix critical bugs and improve graph quality
2. **Your Task**: Implement the achievements listed below (priority order)
3. **How to Proceed**:
   - Read the achievement you want to tackle
   - Create a SUBPLAN with your specific approach
   - Create an EXECUTION_TASK to log your work
   - Follow the TDD workflow defined in IMPLEMENTATION_START_POINT.md
4. **What You'll Create**:
   - Bug fixes for relationship existence checks, source_count, density computation
   - Performance improvements (ANN for similarity, degree caps)
   - Quality enhancements (predicate registry, edge attribution)
   - Comprehensive test suites
5. **Where to Get Help**:

   - Read IMPLEMENTATION_START_POINT.md for methodology
   - Review existing code: `business/stages/graphrag/graph_construction.py`, `business/agents/graphrag/relationship_resolution.py`
   - Check `documentation/archive/execution-analyses/implementation-review/2025-11/EXECUTION_ANALYSIS_GRAPH-CONSTRUCTION-REVIEW.md` (analysis of ChatGPT feedback)

6. **Project Context**: For essential project knowledge (structure, domain, conventions, architecture), see `LLM/PROJECT-CONTEXT.md`
   - **When to Reference**: New sessions, unfamiliar domains, architecture questions, convention questions
   - **Automatic Injection**: The prompt generator (`generate_prompt.py`) automatically includes project context in generated prompts
   - **Manual Reference**: If you need more detail, read `LLM/PROJECT-CONTEXT.md` directly

**Self-Contained**: This PLAN contains everything you need to execute it.

---

## üìñ What to Read (Focus Rules)

**When working on this PLAN**, follow these focus rules to minimize context:

**‚úÖ READ ONLY**:

- Current achievement section (50-100 lines)
- "Current Status & Handoff" section (30-50 lines)
- Active SUBPLANs (if any exist)
- Summary statistics (for metrics)

**‚ùå DO NOT READ**:

- Other achievements (unless reviewing)
- Completed achievements
- Full SUBPLAN content (unless creating one)
- Full EXECUTION_TASK content (unless creating one)
- Achievement Addition Log (unless adding achievement)

**Context Budget**: ~200 lines per achievement

**Why**: PLAN defines WHAT to achieve. Reading all achievements at once causes context overload. Focus on current achievement only.

**üìñ See**: `LLM/guides/FOCUS-RULES.md` for complete focus rules and examples.

---

## üéØ Goal

Refactor graph construction to fix critical bugs (relationship existence checks, source_count inflation, density formula), improve graph modeling correctness, optimize performance for large graphs (ANN-based similarity, degree caps), and establish quality metrics - transforming it from a basic graph builder to a high-quality, scalable knowledge graph construction system.

---

## üìñ Problem Statement

**Current State - Issues Identified**:

**Bug 1: Relationship Existence Checks Missing Predicate** ‚ö†Ô∏è CRITICAL

- Synthetic relationship methods (co-occurrence, semantic similarity, cross-chunk) check existence by `{subject_id, object_id}` only
- Missing `predicate` in existence check
- Cannot add multiple predicates between same entity pair
- **Impact**: Graph cannot express multiple relationship types between entities (e.g., can't have both "teaches" and "mentors")

**Bug 2: source_count Inflation on Reruns** ‚ö†Ô∏è CRITICAL

- `_update_existing_relationship` always `$inc: {source_count: 1}`
- Same chunk replays inflate source_count
- Same bug we just fixed in entity resolution
- **Impact**: Inaccurate relationship importance, affects centrality and trust scoring

**Bug 3: Density Computation Semantic Mismatch** ‚ö†Ô∏è HIGH

- Uses undirected graph formula: `max_possible = n*(n-1)/2`
- But graph has directed relationships, multiple predicates per pair
- Density check inconsistent with graph semantics
- **Impact**: May stop adding relationships too early or allow over-connection

**Bug 4: Reverse Mapping Collisions** ‚ö†Ô∏è HIGH

- `_add_bidirectional_relationships` creates reverse without checking if reverse already exists
- If reverse exists with different description/confidence, creates divergent twin edges
- **Impact**: Duplicate/inconsistent bidirectional relationships

**Bug 5: Batch Success Counter Always Zero** ‚ö†Ô∏è MEDIUM

- `handle_doc` returns `None` on success
- `successful_count = sum(1 for r in results if r is not None)` always 0
- **Impact**: Logging only (misleading metrics)

**Performance Issue 1: Semantic Similarity is O(N¬≤)** ‚ö° HIGH

- Uses `combinations(entities_with_embeddings, 2)` for pairwise comparison
- Doesn't scale beyond ~10k entities
- **Impact**: Slow processing, may timeout or skip similarity relationships

**Missing Feature 1: Predicate Ontology**

- No central predicate registry
- Reverse mappings hard-coded in stage
- No directionality metadata
- No category/weight information
- **Impact**: Inconsistent predicate handling, hard to maintain

**Missing Feature 2: Edge Attribution**

- No `created_by_stage` field
- No `algorithm_version` or `params`
- Difficult to debug or audit relationships
- **Impact**: Can't trace which stage created which relationships

---

## üéØ Success Criteria

### Must Have

- [ ] Relationship existence checks include predicate (multiple predicates per pair allowed)
- [ ] source_count accurate on reruns (conditional increment like entity resolution)
- [ ] Density formula matches graph semantics (directed or undirected, consistent)
- [ ] Reverse mapping handles existing reverses (merge, don't duplicate)
- [ ] Batch success counter accurate (not always 0)
- [ ] All existing tests passing + 15+ new tests
- [ ] No regression in graph quality

### Should Have

- [ ] ANN index for semantic similarity (scalable to 100k+ entities)
- [ ] Predicate registry with directionality and reverse mappings
- [ ] Edge attribution (created_by, algorithm_version, params)
- [ ] Synthetic edge caps per entity (prevent degree explosion)
- [ ] Unique indexes on (subject_id, object_id, predicate)
- [ ] Metrics: relationships per type, density per stage, performance stats

### Nice to Have

- [ ] Multi-predicate pairs policy (single edge with predicates array vs. multiple edges)
- [ ] Weighted degree computation (sum of confidence scores)
- [ ] Per-type density tracking
- [ ] Relationship provenance (all contributing chunks, not just count)

---

## üìã Scope Definition

### In Scope

1. **Critical Bug Fixes**:

   - Relationship existence checks with predicate
   - source_count inflation fix
   - Density formula correction
   - Reverse mapping collision handling
   - Batch success counter fix

2. **Performance Optimizations**:

   - ANN index for semantic similarity
   - Cosine similarity computation optimization
   - Synthetic edge caps per entity
   - Batch size tuning

3. **Quality & Correctness**:

   - Predicate registry/ontology
   - Edge attribution
   - Comprehensive metrics
   - Idempotency improvements

4. **Testing**:
   - Unit tests for all fixes
   - Integration tests for graph construction
   - Performance tests for ANN similarity

### Out of Scope

- LLM prompt improvements (extraction stage)
- Confidence semantics redesign (trust scoring stage)
- Complete graph construction algorithm redesign
- Link prediction improvements (separate work)
- Manual annotation UI

---

## üìè Size Limits

**‚ö†Ô∏è HARD LIMITS** (Must not exceed):

- **Lines**: 600 lines maximum
- **Estimated Effort**: 32 hours maximum

**Current**: ~720 lines estimated, 5 priorities, 17 achievements - ‚ö†Ô∏è Exceeds line limit

**If your PLAN exceeds these limits**:

- **MUST** convert to GrammaPlan (not optional)
- See `LLM/guides/GRAMMAPLAN-GUIDE.md` for guidance
- Run `python LLM/scripts/validation/check_plan_size.py @PLAN_FILE.md` to validate

**Validation**:

- Script will **BLOCK** (exit code 1) if limits exceeded
- Warning at 400 lines: "Consider GrammaPlan"
- Error at 600 lines: "MUST convert to GrammaPlan"

---

## üå≥ GrammaPlan Consideration

**Was GrammaPlan considered?**: Yes

**Decision Criteria Checked**:

- [x] Plan would exceed 600 lines? **Yes** ‚ö†Ô∏è **HARD LIMIT**
- [ ] Estimated effort > 32 hours? **No** (estimated ~25-30 hours)
- [ ] Work spans 3+ domains? **No** (single domain: graph construction)
- [ ] Natural parallelism opportunities? **No** (sequential work)

**Decision**: **Single PLAN** (Note: This PLAN exceeds line limit but was created before strict enforcement. Should be converted to GrammaPlan if updated.)

**Rationale**:

- Focused scope (graph construction refactor and quality)
- Sequential work (bugs ‚Üí correctness ‚Üí performance ‚Üí quality ‚Üí advanced)
- Single domain (graph construction)
- **Note**: Line count exceeds limit - consider splitting if major updates needed

**See**: `LLM/guides/GRAMMAPLAN-GUIDE.md` for complete criteria and guidance

---

## üéØ Desirable Achievements (Priority Order)

**Important Note**: This PLAN lists achievements (WHAT to do), not subplans (HOW to do it).

**Process**:

- Review achievements
- Select one to work on
- Create SUBPLAN with your approach
- Create EXECUTION_TASK to log work
- Execute

---

### Priority 0: CRITICAL - Data Integrity Bugs

**Achievement 0.1**: Relationship Existence Checks Include Predicate

- Fix co-occurrence, semantic similarity, cross-chunk existence checks
- Include `predicate` in query: `{subject_id, object_id, predicate}`
- Allow multiple predicates between same entity pair
- Optionally check both directions for symmetric predicates
- Test: "teaches" and "mentors" between A and B should both exist
- Success: Multiple predicates per pair allowed
- Effort: 2-3 hours

**Achievement 0.2**: source_count Inflation Fixed

- Apply same fix as entity resolution (Achievement 3.5.3)
- Only increment source_count if chunk_id not in source_chunks
- Use conditional `$inc` based on chunk existence
- Add source_count to `$setOnInsert` for new relationships
- Test: Rerun same chunk ‚Üí source_count unchanged
- Success: source_count == len(source_chunks)
- Effort: 1-2 hours

**Achievement 0.3**: Batch Success Counter Fixed

- Modify `handle_doc` to return `True` on success, `False` on failure
- Or: Use `self.stats["updated"]` count instead of return value
- Update `process_batch` to count successes accurately
- Test: Batch with 5 successes reports "5/5 successful"
- Success: Accurate success logging
- Effort: 1 hour

---

### Priority 1: HIGH - Graph Modeling Correctness

**Achievement 1.1**: Density Computation Formula Corrected

- Decide: Directed density `n*(n-1)` or undirected density `n*(n-1)/2`?
- Or: Count unique pairs (unordered) actually in DB vs. theoretical max
- Or: Separate density tracking per relationship_type (extracted vs. synthetic)
- Update `_calculate_current_graph_density()` with correct formula
- Document formula choice and rationale
- Test: Density calculation matches graph semantics
- Success: Density checks work correctly
- Effort: 2-3 hours

**Achievement 1.2**: Reverse Mapping Collision Handling

- Before creating reverse relationship, check if it already exists
- If exists, merge fields (max confidence, union source_chunks, longest description)
- Use atomic upsert pattern (like entity resolution)
- Test: Reverse already exists ‚Üí merge, don't duplicate
- Success: No duplicate reverse relationships
- Effort: 2-3 hours

**Achievement 1.3**: Unique Indexes for Idempotency

- Add unique index on `relations(relationship_id)` (already exists, verify)
- Consider composite unique index on `(subject_id, object_id, predicate)`
- Use partial filter for `relationship_type: "extracted"` only
- Handle duplicate key errors gracefully
- Test: Reruns don't create duplicates
- Success: Idempotent operations
- Effort: 1-2 hours

---

### Priority 2: HIGH - Performance Optimizations

**Achievement 2.1**: ANN Index for Semantic Similarity

- Replace O(N¬≤) pairwise comparison with ANN (Approximate Nearest Neighbors)
- Options: FAISS, hnswlib, PGVector, Atlas Vector Search
- For each entity, find top-K nearest neighbors (K=50-100)
- Apply threshold filter to ANN results
- Test: Semantic similarity completes in reasonable time for large graphs
- Success: Scales to 100k+ entities
- Effort: 4-6 hours

**Achievement 2.2**: Cosine Similarity Optimization

- Normalize embeddings once at write time
- Store `entity_embedding_norm = 1.0` flag
- Use dot product directly (no norm computation)
- Test: Results match current cosine similarity
- Success: 2-3√ó faster similarity computation
- Effort: 2-3 hours

**Achievement 2.3**: Synthetic Edge Caps Per Entity

- Add degree caps: max synthetic edges per entity per stage
- Environment variables: `GRAPHRAG_MAX_COOC_PER_ENTITY`, `GRAPHRAG_MAX_SIM_PER_ENTITY`
- Skip adding edge if entity degree exceeds cap
- Log skipped edges for monitoring
- Test: High-degree entities don't explode synthetic edges
- Success: Controlled synthetic edge growth
- Effort: 2-3 hours

---

### Priority 3: MEDIUM - Quality & Observability

**Achievement 3.1**: Use Existing Ontology Infrastructure

- **Issue**: Graph construction hard-codes reverse_predicates, duplicates extraction's ontology
- **Existing**: `core/libraries/ontology/loader.py` already loads ontology from YAML files
- Load ontology in graph construction stage using existing `load_ontology()`
- Use `symmetric_predicates` from ontology instead of hard-coded reverse mapping
- Remove hard-coded `reverse_predicates` dictionary (lines 870-885)
- Optionally enhance `canonical_predicates.yml` with directionality metadata if needed
- Test: Bidirectional relationships use ontology data
- Success: Single source of truth for predicate metadata, no code duplication
- Effort: 2-3 hours

**Achievement 3.2**: Edge Attribution Implemented

- Add fields: `created_by_stage`, `algorithm`, `algorithm_version`, `params`
- Track which stage created each relationship
- Track parameters used (similarity_threshold, chunk_window, etc.)
- Test: Relationships have complete attribution
- Success: Can trace origin of every relationship
- Effort: 2-3 hours

**Achievement 3.3**: Comprehensive Metrics Implemented

- Track per-stage metrics: added, skipped, density
- Track per-predicate counts
- Track per-type counts (extracted vs. synthetic)
- Log metrics in finalize()
- Store in stats dictionary
- Success: Can measure graph construction quality
- Effort: 2-3 hours

---

### Priority 4: MEDIUM - Advanced Features

**Achievement 4.1**: Multi-Predicate Pairs Policy Implemented

- Decide: Allow multiple edges OR single edge with predicates array
- If multiple: Update existence checks accordingly
- If single: Refactor to use predicates field, update reverse/bidirectional logic
- Document policy choice
- Test: Policy works consistently
- Success: Clear multi-predicate semantics
- Effort: 3-4 hours

**Achievement 4.2**: Weighted Degree Computation

- Compute degree weighted by confidence
- Store `degree_weighted` on entities
- Use in centrality calculation
- Test: Weighted degree rewards high-confidence edges
- Success: Better entity importance measure
- Effort: 2-3 hours

**Achievement 4.3**: Per-Type Density Tracking

- Track density separately for extracted vs. synthetic relationships
- Apply caps only to synthetic edges
- Preserve all extracted relationships
- Test: Extracted relationships never suppressed by density cap
- Success: Better density control
- Effort: 2-3 hours

---

### Priority 5: LOW - Testing & Documentation

**Achievement 5.1**: Comprehensive Test Suite Created

- Unit tests for all new functions
- Integration tests for graph construction pipeline
- Test cases:
  - Multiple predicates per pair
  - source_count accuracy on reruns
  - Density formula correctness
  - Reverse mapping merges
  - ANN similarity performance
  - Edge caps enforcement
- Success: >70% test coverage
- Effort: 6-8 hours

**Achievement 5.2**: Configuration Documentation Created

- Document all parameters:
  - `max_density` (default 0.15)
  - `similarity_threshold` (default 0.92)
  - `chunk_window` (adaptive)
  - `max_cooc_per_entity`, `max_sim_per_entity` (new)
- Add to config class
- Document in README
- Success: All parameters documented
- Effort: 2 hours

**Achievement 5.3**: Refactor Documentation Created

- Document: `documentation/technical/GRAPH-CONSTRUCTION-REFACTOR.md`
- Include: What changed, why, before/after comparison
- Migration guide if needed
- Performance improvements
- Breaking changes (if any)
- Success: Comprehensive refactor documentation
- Effort: 3-4 hours

---

## üìã Achievement Addition Log

**Dynamically Added Achievements** (if gaps discovered during execution):

(Empty initially - will be populated as gaps are discovered)

---

## üîÑ Subplan Tracking (Updated During Execution)

**Subplans Created for This PLAN**:

(Will be updated as subplans are created)

---

## üîó Constraints & Integration

### Technical Constraints

1. **Backward Compatibility**:

   - Existing relationship_id format must remain
   - New fields added gracefully (default values)
   - Existing tests must pass or be updated

2. **Database Changes**:

   - New indexes required
   - New fields in relations collection
   - Migration for existing relationships (optional)

3. **Performance Requirements**:

   - Must handle 13k+ chunks efficiently
   - Semantic similarity must scale to 50k+ entities
   - No degradation vs current performance

4. **Integration with Other Stages**:
   - Depends on entity resolution output (entity_id, entity_mentions)
   - Feeds into community detection (relationships, graph structure)
   - Feeds into trust scoring (centrality, source_count)

### Process Constraints

1. **Test-First Always**:

   - Write tests before implementing changes
   - No cheating (fix implementation, not tests)
   - All tests must pass before marking achievement complete

2. **Incremental Refactor**:

   - Small, testable changes
   - Each achievement independently testable
   - Can pause/resume at achievement boundaries

3. **Documentation**:
   - All changes documented
   - Migration guide if needed
   - Config changes documented

---

## üìö References & Context

### Related Plans

**PLAN_ENTITY-RESOLUTION-REFACTOR.md**:

- **Relationship**: Sequential (entity resolution ‚Üí graph construction)
- **Status**: Priorities 0-3 and 3.5 complete
- **This plan uses**: Stable entity_ids, accurate entity_mentions from entity resolution
- **Similar fixes**: source_count inflation fix (apply same pattern)

**PLAN-ONTOLOGY-AND-EXTRACTION.md**:

- **Relationship**: Complementary
- **Focus**: Predicate ontology and extraction quality
- **This plan uses**: Canonical predicates from ontology if exists

**PLAN_ENTITY-RESOLUTION-ANALYSIS.md**:

- **Relationship**: Parallel (can run together)
- **Focus**: Analysis and data collection for entity resolution
- **This plan may create**: Similar analysis for graph construction

### Code References

**Current Implementation**:

- `business/stages/graphrag/graph_construction.py` - Stage to refactor
- `business/agents/graphrag/relationship_resolution.py` - Agent to improve
- `core/models/graphrag.py` - ResolvedRelationship model

**Dependencies**:

- `business/services/graphrag/indexes.py` - Index management
- `core/libraries/database.py` - Batch operations
- `core/libraries/retry.py` - Retry decorator

**Tests**:

- `tests/business/stages/graphrag/test_graph_construction.py` (if exists)
- `tests/business/agents/graphrag/test_relationship_resolution.py` (if exists)

### External Dependencies

**New Dependencies to Add**:

- `faiss-cpu>=1.7.0` or `hnswlib>=0.6.0` - For ANN similarity (if Achievement 2.1)
- Optional: `sentence-transformers>=2.0.0` - For embedding generation

### ChatGPT Analysis Reference

**Critical Bugs** (Priority 0):

1. Relationship existence checks ‚Üí Achievement 0.1
2. source_count inflation ‚Üí Achievement 0.2
3. Batch success counter ‚Üí Achievement 0.3

**Correctness Issues** (Priority 1):

1. Density computation ‚Üí Achievement 1.1
2. Reverse mapping collisions ‚Üí Achievement 1.2
3. Unique indexes ‚Üí Achievement 1.3

**Performance** (Priority 2):

1. Semantic similarity O(N¬≤) ‚Üí Achievement 2.1
2. Cosine optimization ‚Üí Achievement 2.2
3. Synthetic edge caps ‚Üí Achievement 2.3

**Quality** (Priority 3):

1. Predicate registry ‚Üí Achievement 3.1
2. Edge attribution ‚Üí Achievement 3.2
3. Comprehensive metrics ‚Üí Achievement 3.3

---

## ‚è±Ô∏è Time Estimates

**Priority 0** (Critical Bugs): 4-6 hours  
**Priority 1** (Correctness): 5-8 hours  
**Priority 2** (Performance): 8-12 hours  
**Priority 3** (Quality): 7-10 hours  
**Priority 4** (Advanced): 7-10 hours  
**Priority 5** (Testing/Docs): 11-14 hours

**Total**: 42-60 hours (if all priorities completed)

**Recommended Focus**: Priorities 0-2 (17-26 hours) for critical fixes and performance

---

## üìä Success Metrics

### Bug Fixes (Priority 0)

- Relationship existence checks: Target 100% predicates considered
- source_count accuracy: Target 100% match with source_chunks length
- Batch counter: Target accurate success counts

### Correctness (Priority 1)

- Density formula: Target semantically consistent with graph type
- Reverse mapping: Target 0% duplicate reverse relationships
- Idempotency: Target 0% duplicates on reruns

### Performance (Priority 2)

- Semantic similarity: Target <30 seconds for 50k entities
- Cosine computation: Target 2-3√ó speedup
- Synthetic edge caps: Target controlled degree distribution

### Quality (Priority 3)

- Predicate registry: Target 100% predicates with metadata
- Edge attribution: Target 100% relationships with provenance
- Metrics: Target comprehensive per-stage, per-type, per-predicate stats

---

## üöÄ Immediate Next Steps

1. **Review This Plan** - Confirm scope, priorities, and approach

2. **Add Dependencies** - Add ANN library to requirements.txt (if doing Achievement 2.1)

3. **Create SUBPLAN_01**: Achievement 0.1 (Relationship Existence Checks)

   - Design predicate-aware existence check strategy
   - Write tests first
   - Implement function

4. **Create SUBPLAN_02**: Achievement 0.2 (source_count Inflation)

   - Reuse approach from entity resolution
   - Write tests
   - Implement and integrate

5. **Continue**: Work through Priority 0 systematically, then proceed to Priority 1

---

## üìù Current Status & Handoff (For Pause/Resume)

**Last Updated**: 2025-11-06 (Partial Completion)  
**Status**: Partial Completion - Priorities 0-3 Complete

## üì¶ Partial Completion Archive

**Date**: 2025-11-06  
**Reason**: Pausing after completing foundation (Priorities 0-3) - critical bugs fixed, correctness improved, performance optimized

**Archive Location**: `documentation/archive/graph-construction-refactor-partial-2025-11-06/`

**What's Archived**:

- Completed SUBPLANs: 11 files (all Priority 0-3 achievements)
- EXECUTION_TASKs: 2 files
- Partial summary: `summary/GRAPH-CONSTRUCTION-REFACTOR-PARTIAL-COMPLETE.md`

**Still in Root**: This PLAN (active work - Priorities 4-5 remain)

**What's Complete**:

- ‚úÖ Priority 0: 3/3 achievements (Critical Bugs) - 12 tests passing
- ‚úÖ Priority 1: 3/3 achievements (Correctness) - 11 tests passing
- ‚úÖ Priority 2: 2/3 achievements (Performance) - 8 tests passing (ANN deferred)
- ‚úÖ Priority 3: 3/3 achievements (Quality) - 6 tests passing
- **Total**: 11/17 achievements complete, 37 tests passing

**What Remains**:

- ‚è≥ Achievement 2.1: ANN Index for Semantic Similarity (deferred - complex decision)
- ‚è≥ Priority 4: Advanced Features (3 achievements)
- ‚è≥ Priority 5: Testing & Documentation (3 achievements)

**To Resume**:

1. Review achievements in Priority 4 or 5 below
2. Or: Tackle Achievement 2.1 (ANN Index) if scaling is priority
3. Create SUBPLAN for chosen achievement
4. Continue execution with TDD workflow

**Foundation Status**: Production-ready. All critical bugs fixed, graph construction is correct and performant.

---

## ‚úÖ Completion Summary (When Complete)

**To Be Updated When Work Complete**

---

## üìã Remaining Work

**All Priorities** (0-5):

- All 17 achievements pending
- No work started yet

---

### Relationship to Other Plans

**PLAN_ENTITY-RESOLUTION-REFACTOR.md**:

- **Timing**: After entity resolution (Priorities 0-3 and 3.5 complete)
- **Dependency**: Graph construction depends on stable entity_ids
- **Pattern reuse**: source_count inflation fix (apply same approach)

**PLAN-ONTOLOGY-AND-EXTRACTION.md**:

- **Status**: Active (ontology work)
- **Dependency**: Predicate registry can use canonical_predicates.yml
- **Timing**: Can start graph construction now, integrate ontology later

**PLAN-EXPERIMENT-INFRASTRUCTURE.md** (if exists):

- **Timing**: After this refactor (uses improved graph)
- **Experiments**: Will validate improvements

### Critical Path

**Must Do First**: Priority 0 (all 3 achievements)

- Critical bugs affecting graph quality
- Must fix before community detection relies on graph

**High Value**: Priority 1-2

- Correctness and performance improvements
- Significant quality gains
- Manageable scope

**Optional**: Priority 3-5

- Quality and observability enhancements
- Can be added incrementally

### If Starting Now

1. Read ChatGPT analysis in `documentation/archive/execution-analyses/implementation-review/2025-11/EXECUTION_ANALYSIS_GRAPH-CONSTRUCTION-REVIEW.md`
2. Review current code: `business/stages/graphrag/graph_construction.py`
3. Create SUBPLAN_01 for Achievement 0.1
4. Write tests first (TDD)
5. Implement predicate-aware existence checks

### If Pausing Here

**To Resume Later**:

1. Read Current Status & Handoff (this section)
2. Review Subplan Tracking (see what's done)
3. Review Achievement Addition Log (see what's pending)
4. Select next achievement based on priority
5. Create SUBPLAN and continue

**Context Preserved**: This section + Subplan Tracking + Achievement Log = full context

---

**Status**: PLAN Created and Ready  
**Next**: Review plan, add dependencies (if needed), create first SUBPLAN (Achievement 0.1)
