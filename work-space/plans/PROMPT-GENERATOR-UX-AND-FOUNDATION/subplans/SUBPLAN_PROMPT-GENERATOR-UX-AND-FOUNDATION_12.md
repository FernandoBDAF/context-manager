# SUBPLAN: Comprehensive Inline Documentation

**Type**: SUBPLAN  
**Mother Plan**: PLAN_PROMPT-GENERATOR-UX-AND-FOUNDATION.md  
**Plan**: PROMPT-GENERATOR-UX-AND-FOUNDATION  
**Achievement Addressed**: Achievement 1.2 (Comprehensive Inline Documentation)  
**Achievement**: 1.2  
**Status**: âœ… Complete  
**Created**: 2025-11-10 01:50 UTC  
**Completed**: 2025-11-10 06:30 UTC  
**Estimated Effort**: 5-6 hours  
**Actual Effort**: 1.5 hours

**File Location**: `work-space/plans/PROMPT-GENERATOR-UX-AND-FOUNDATION/subplans/SUBPLAN_PROMPT-GENERATOR-UX-AND-FOUNDATION_12.md`

**Size**: 200-600 lines

---

## ğŸ¯ Objective

Transform `generate_prompt.py` into a self-documenting source of truth by adding comprehensive architecture overview, detailed function docstrings, and inline comments for complex logic, with special emphasis on documenting all 11 bug fixes and their context. This preserves institutional knowledge and enables safe refactoring.

---

## ğŸ“‹ Deliverables

### 1. Enhanced Module Docstring (~200 lines)

**Location**: Top of `generate_prompt.py` (after imports)

**Content**:

- **Purpose**: What this script does and why it exists
- **Architecture Overview**: State machine diagram showing 7 workflow states
- **Bug Fix History**: All 11 bugs with fixes and lessons
- **Design Philosophy**: Interactive mode as primary UI, structured metadata future
- **Refactor Notes**: What needs improvement, why, and how
- **Usage Examples**: Common workflows with --interactive flag
- **Testing Status**: Current coverage, what's tested, what's not
- **Future Vision**: Path to North Star CLI platform

**Format**:

```python
"""
Generate Prompt - LLM Methodology Workflow Automation

PURPOSE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[Detailed purpose]

ARCHITECTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[State machine diagram]

BUG FIX HISTORY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[All 11 bugs documented]

DESIGN PHILOSOPHY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[Interactive mode, metadata future]

...
"""
```

### 2. Comprehensive Function Docstrings (24 functions)

**Template for Each Function**:

```python
def function_name(args) -> return_type:
    """
    One-line summary.

    Detailed description of what this function does and why it exists.

    Bug Fixes Incorporated:
        - Bug #N: Description of fix
        - Bug #M: Description of fix

    Args:
        arg1: Description
        arg2: Description

    Returns:
        Description of return value

    Raises:
        ExceptionType: When and why

    Examples:
        >>> function_name(example_input)
        expected_output

    Test Coverage:
        - test_function_name() in test_file.py
        - Edge cases: test_edge_case()

    Known Issues:
        - Issue description (if any)

    Future Improvements:
        - Planned enhancement (if any)
    """
```

**Priority Functions** (document first):

1. `detect_workflow_state()` - Core state detection (Bugs #6-7 fixes)
2. `detect_plan_filesystem_conflict()` - Conflict detection (Bug #2 fix)
3. `detect_workflow_state_filesystem()` - Filesystem detection (Bug #3 fix)
4. `find_next_achievement_hybrid()` - Achievement finding
5. `parse_plan_file()` - PLAN parsing
6. `output_interactive_menu()` - Interactive UI (Achievement 0.3)
7. `resolve_folder_shortcut()` - @folder shortcut (Achievement 0.1)
8. `extract_plan_statistics()` - Statistics (Achievement 0.2)

### 3. Inline Comments for Complex Logic

**Locations to Document**:

**Bug #6 Fix** (Multi-execution count from SUBPLAN table):

```python
# Bug #6 Fix: Read planned execution count from SUBPLAN table
# Previously: Only counted files on filesystem (incorrect)
# Now: Parse "## ğŸ”„ Active EXECUTION_TASKs" table for planned count
# Why: SUBPLAN defines how many executions are planned
# Reference: EXECUTION_ANALYSIS_SEVEN-BUGS-FINAL-SYNTHESIS.md
```

**Bug #7 Fix** (Create next execution from filesystem):

```python
# Bug #7 Fix: Calculate next execution from filesystem, not SUBPLAN table
# Previously: Trusted "â³ Next" in SUBPLAN table (could be outdated)
# Now: Scan filesystem for highest completed, calculate next as highest + 1
# Why: Filesystem is source of truth for completion
# Reference: EXECUTION_ANALYSIS_SEVEN-BUGS-FINAL-SYNTHESIS.md
```

**Bug #2 Fix** (Conflict detection):

```python
# Bug #2 Fix: Detect PLAN/filesystem conflicts before proceeding
# Problem: PLAN "Current Status & Handoff" can drift out of sync
# Solution: Compare PLAN state vs filesystem state, report conflicts
# Reference: EXECUTION_ANALYSIS_PROMPT-GENERATOR-CONFLICT-DETECTION.md
```

**Bug #3 Fix** (Read entire file):

```python
# Bug #3 Fix: Read entire file for completion status
# Previously: Only read first 500 chars (missed completion markers)
# Now: Read full file content
# Reference: EXECUTION_ANALYSIS_EXECUTION-STATUS-DETECTION-BUGS.md
```

**Bug #8 Fix** (Emoji-agnostic):

```python
# Bug #8 Fix: Emoji-agnostic regex for section matching
# Previously: Hardcoded specific emojis (ğŸ¨, ğŸ“, ğŸ”Œ)
# Now: Matches ANY emoji [\U0001F300-\U0001F9FF]
# Why: LLMs choose contextually appropriate emojis
# Reference: EXECUTION_ANALYSIS_SUBPLAN-EXTRACTION-BUG-8.md
```

**Bug #9 Fix** (Shared module):

```python
# Bug #9 Fix: Shared path_resolution.py module
# Previously: Path resolution duplicated in 3 scripts
# Now: Single shared module, imported by all
# Reference: EXECUTION_ANALYSIS_SUBPLAN-PROMPT-GENERATOR-MISSING-PATH-RESOLUTION-BUG-9.md
```

**Bug #10-11 Fixes** (Path handling):

```python
# Bug #10-11 Fix: Use .name for @ shorthand, not full Path
# Previously: f"@{path}" included full path (invalid)
# Now: f"@{path.name}" uses just filename
# Reference: EXECUTION_ANALYSIS_GENERATE-PROMPT-INCORRECT-SUBPLAN-PATH-BUG-10.md
```

### 4. Documentation Review

- Verify all 24 functions documented
- Check inline comments complete
- Ensure bug fixes annotated
- Validate examples work
- Check for clarity

---

## ğŸ¨ Approach

**Strategy**: Document systematically from top to bottom, starting with module overview, then priority functions (most complex/most bugs), then remaining functions, then inline comments for bug fixes.

**Documentation Philosophy**:

1. **Code as Source of Truth** - Documentation lives in code, not separate docs
2. **Bug Context Preserved** - Every bug fix annotated with why and reference
3. **Examples Included** - Show how to use each function
4. **Test References** - Link to test coverage
5. **Future-Oriented** - Note planned improvements

**Method**:

1. **Phase 1**: Module docstring (architecture, bugs, philosophy)
2. **Phase 2**: Priority function docstrings (8 functions)
3. **Phase 3**: Remaining function docstrings (16 functions)
4. **Phase 4**: Inline comments (bug fixes, complex logic)
5. **Phase 5**: Review and verification

---

## ğŸ”„ Execution Strategy

**Execution Count**: Single

**Rationale**: This is a cohesive documentation effort that should be completed in one systematic pass to ensure consistency in style, depth, and coverage. All documentation is interconnected (module overview references functions, functions reference bugs, bugs reference analyses).

**Execution Plan**:

**EXECUTION_TASK_12_01**: Comprehensive Inline Documentation

- Phase 1: Module docstring (90 min)
- Phase 2: Priority functions (120 min)
- Phase 3: Remaining functions (90 min)
- Phase 4: Inline comments (60 min)
- Phase 5: Review (30 min)
- Estimated: 5-6 hours

**Dependencies**:

- Achievement 1.1 complete (tests provide coverage references)
- All 11 bugs documented (references available)

---

## ğŸ¯ Module Docstring Structure

### Section 1: Purpose & Overview (30 lines)

```python
"""
Generate Prompt - LLM Methodology Workflow Automation

PURPOSE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

This script automates prompt generation for the LLM development methodology,
supporting the complete PLAN â†’ SUBPLAN â†’ EXECUTION_TASK workflow.

Primary UI: Interactive mode (--interactive flag)
- Two-stage experience: Choose workflow â†’ Handle output
- Smart defaults: Enter = copy to clipboard
- Context-aware: Options adapt to workflow state

Current State: Production-ready for daily use
- 96 tests (100% passing)
- Interactive mode stable
- 11 bugs fixed and documented
- Ready for refactoring

Strategic Direction: Foundation for North Star CLI platform
- This script will be modularized (Priority 2)
- Metadata support will be added (Priority 2)
- But foundation is now solid
"""
```

### Section 2: Architecture Overview (50 lines)

**State Machine Diagram**:

```python
"""
ARCHITECTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Workflow State Machine (7 states):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                     â”‚
â”‚  START â†’ Detect State â†’ Route to Handler â†’ Generate Prompt â†’ Outputâ”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

States:
1. create_subplan      - No SUBPLAN exists
2. create_execution    - SUBPLAN exists, no EXECUTION
3. continue_execution  - EXECUTION in progress
4. create_next_execution - Multi-execution, need next
5. synthesize_results  - All EXECUTIONs complete
6. next_achievement    - Current achievement complete
7. plan_complete       - All achievements done

Detection Logic:
- Filesystem-based (primary) - Check what files exist
- Text-based (fallback) - Parse markdown headers
- Conflict detection - Compare PLAN vs filesystem

Output Handling:
- Interactive mode: Two-stage menu
- Non-interactive: Print + auto-copy to clipboard
"""
```

### Section 3: Bug Fix History (70 lines)

```python
"""
BUG FIX HISTORY (All 11 Bugs Documented)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Parsing Bugs (8 bugs - 73% of total):
  Bug #1: Overly broad regex for completion detection
  Bug #2: PLAN/filesystem conflict (manual updates failing)
  Bug #3: Only reading 500 chars for status (missed markers)
  Bug #4: Template command instead of actual filename
  Bug #5: Missing section name ("Implementation Strategy")
  Bug #6: Multi-execution count from filesystem (should be SUBPLAN)
  Bug #7: Trusting outdated SUBPLAN table (should scan filesystem)
  Bug #8: Missing emoji variation (ğŸ¯ not in fallback chain)

Architectural Bugs (3 bugs - 27% of total):
  Bug #9: Missing @ shorthand in other scripts (code duplication)
  Bug #10: Incorrect path format in commands (@{path} vs @{path.name})
  Bug #11: Silent failure in --subplan-only (empty error message)

Root Cause: Fragile text parsing of evolving markdown
Solution: Structured metadata (Priority 2, Achievement 2.2)

Complete Documentation: work-space/analyses/implementation_automation/
  - 23 analysis documents (~14,510 lines)
  - INDEX.md catalog
  - 2 case studies with patterns
"""
```

### Section 4: Design Philosophy (30 lines)

```python
"""
DESIGN PHILOSOPHY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Interactive Mode as Primary UI
   - Two-stage design (pre-execution + post-generation)
   - Smart defaults (Enter = copy)
   - Context-aware options
   - Achievement 0.3 implementation

2. Filesystem as Source of Truth
   - File existence = state
   - Completion markers validated
   - Conflict detection when drift occurs

3. Backward Compatibility
   - Non-interactive mode still works
   - Full paths still supported
   - Gradual migration approach

4. Test-Driven Quality
   - 96 tests (100% passing)
   - New features: 100% tested
   - Legacy code: 75% untested (being addressed)

5. Future: Structured Metadata
   - YAML frontmatter for state
   - Eliminates parsing bugs
   - Priority 2 (Achievement 2.2)
"""
```

### Section 5: Refactor Notes (20 lines)

```python
"""
REFACTOR NOTES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Current: 1,920 lines, 24 functions, single file
Target: 6 modules, <500 lines each

Planned Extraction (Priority 2, Achievement 2.1):
  - plan_parser.py (PLAN parsing)
  - state_detector.py (workflow detection)
  - conflict_validator.py (conflict detection)
  - prompt_builder.py (prompt generation)
  - cli_helpers.py (interactive menu, utilities)
  - generate_prompt.py (orchestration only)

Why Not Now: Need 90% test coverage first (Priority 1, Achievement 1.3)
When: After Achievement 1.3 complete (safe to refactor)
"""
```

---

## ğŸ”„ Execution Strategy

**Execution Count**: Single

**Rationale**: Documentation is a cohesive task that requires consistent style, depth, and cross-referencing. Completing in one pass ensures:

- Consistent documentation style
- Complete cross-references (functions reference each other)
- Comprehensive bug annotations
- Unified architecture narrative

**Execution Plan**:

**EXECUTION_TASK_12_01**: Comprehensive Inline Documentation

- Phase 1: Module docstring (90 min)
- Phase 2: Priority functions (120 min)
- Phase 3: Remaining functions (90 min)
- Phase 4: Inline comments (60 min)
- Phase 5: Review & verification (30 min)
- Estimated: 5-6 hours

**Dependencies**:

- Achievement 1.1 complete (test references available)
- All bug analyses complete (references available)

---

## ğŸ¯ Function Documentation Plan

### Priority 1: Core State Detection (8 functions)

**Most Complex, Most Bugs**:

1. **`detect_workflow_state()`** - Main state detection

   - Bugs #6-7 fixes here
   - Complex logic
   - 7 possible states
   - ~50 lines docstring

2. **`detect_workflow_state_filesystem()`** - Filesystem detection

   - Bug #3 fix (read entire file)
   - Bug #6 fix (count from SUBPLAN)
   - Bug #7 fix (scan filesystem)
   - ~40 lines docstring

3. **`detect_plan_filesystem_conflict()`** - Conflict detection

   - Bug #2 fix
   - Complex comparison logic
   - ~35 lines docstring

4. **`find_next_achievement_hybrid()`** - Achievement finding

   - Multiple methods
   - Fallback chain
   - ~30 lines docstring

5. **`parse_plan_file()`** - PLAN parsing

   - Core parsing logic
   - Achievement extraction
   - ~25 lines docstring

6. **`output_interactive_menu()`** - Interactive UI

   - Achievement 0.3
   - Two-stage design
   - ~30 lines docstring

7. **`resolve_folder_shortcut()`** - @folder resolution

   - Achievement 0.1
   - Bug #9 context
   - ~25 lines docstring

8. **`extract_plan_statistics()`** - Statistics extraction
   - Achievement 0.2
   - ~20 lines docstring

**Total**: ~255 lines for priority functions

### Priority 2: Remaining Functions (16 functions)

**Standard Documentation** (~15 lines each):

- `find_subplan_for_achievement()`
- `find_archive_location()`
- `calculate_handoff_size()`
- `estimate_section_size()`
- `extract_handoff_section()`
- `find_next_achievement_from_plan()`
- `find_next_achievement_from_archive()`
- `is_achievement_complete()`
- `is_plan_complete()`
- `inject_project_context()`
- `generate_prompt()`
- `copy_to_clipboard_safe()`
- `prompt_interactive_menu()` (pre-execution)
- `main()`
- Helper functions (2-3 more)

**Total**: ~240 lines for remaining functions

---

## ğŸ¯ Inline Comment Strategy

### Bug Fix Annotations

**Format**:

```python
# Bug #N Fix: [One-line summary]
# Problem: [What was wrong]
# Solution: [What we did]
# Why: [Rationale]
# Reference: [Analysis document]
```

**Locations**:

1. **Lines ~1050-1100**: Bug #6 fix (SUBPLAN table parsing)
2. **Lines ~1980-2010**: Bug #7 fix (filesystem scan for highest)
3. **Lines ~1200-1250**: Bug #2 fix (conflict detection)
4. **Lines ~950-980**: Bug #3 fix (read entire file)
5. **Lines ~1425-1525**: Achievement 0.3 (interactive menu)
6. **Lines ~1282-1345**: Achievement 0.1 (@folder shortcut)
7. **Lines ~1348-1422**: Achievement 0.2 (statistics)

### Complex Logic Comments

**Multi-Execution Handling**:

```python
# Multi-execution workflow (1 SUBPLAN â†’ N EXECUTION_TASKs)
# Designer creates SUBPLAN with execution plan
# Executors create EXECUTION_TASKs according to plan
# Designer synthesizes results when all complete
```

**Conflict Detection Logic**:

```python
# Conflict detection prevents proceeding with stale information
# Compares PLAN "Current Status & Handoff" vs filesystem reality
# If mismatch: Report conflict, provide resolution guidance
# Trust flags allow bypassing: --trust-plan, --trust-filesystem
```

**State Machine Transitions**:

```python
# State transitions:
# no_subplan â†’ create_subplan (SUBPLAN created)
# subplan_exists â†’ create_execution (EXECUTION created)
# active_execution â†’ continue_execution (work continues)
# subplan_all_executed â†’ next_achievement (achievement done)
```

---

## âœ… Success Criteria

**Completeness**:

- âœ… Module docstring complete (~200 lines)
- âœ… All 24 functions documented
- âœ… All 11 bugs annotated in code
- âœ… Complex logic explained
- âœ… Examples provided

**Quality**:

- âœ… Consistent documentation style
- âœ… Clear and concise
- âœ… References to analyses
- âœ… Test coverage noted
- âœ… Future improvements listed

**Usability**:

- âœ… New developers can understand code
- âœ… Bug fixes are discoverable
- âœ… Refactoring is safer
- âœ… Knowledge preserved
- âœ… Self-documenting

**Verification**:

- âœ… Every function has docstring
- âœ… Every bug fix has comment
- âœ… Module docstring complete
- âœ… Documentation review passed

---

## ğŸš¨ Risks & Mitigations

### Risk 1: Documentation Becomes Outdated

**Mitigation**:

- Document in code (stays synchronized)
- Reference external analyses (detailed context)
- Update during refactoring
- Regular review

### Risk 2: Too Verbose

**Mitigation**:

- One-line summary first
- Details in separate sections
- Examples concise
- Focus on "why" not "what"

### Risk 3: Time Overrun

**Mitigation**:

- Priority functions first (most important)
- Standard template for remaining
- Inline comments last (can defer)
- 5-6 hours is realistic

---

## ğŸ“š Context & References

**Bug Documentation** (All in `work-space/analyses/implementation_automation/`):

- Bug #1-2: PROMPT-GENERATOR-CONFLICT-DETECTION.md
- Bug #3-4: EXECUTION-STATUS-DETECTION-BUGS.md
- Bug #5-7: SEVEN-BUGS-FINAL-SYNTHESIS.md
- Bug #8: SUBPLAN-EXTRACTION-BUG-8.md
- Bug #9: SUBPLAN-PROMPT-GENERATOR-MISSING-PATH-RESOLUTION-BUG-9.md
- Bug #10: GENERATE-PROMPT-INCORRECT-SUBPLAN-PATH-BUG-10.md
- Bug #11: SUBPLAN-ONLY-FLAG-SILENT-FAILURE-BUG-11.md

**Systemic Analyses**:

- PROMPT-GENERATION-SYSTEMIC-ISSUES.md (design flaw analysis)
- PROMPT-GENERATION-LESSONS-FOR-REDESIGN.md (requirements)
- GENERATE-PROMPT-COMPLETE-AUDIT.md (complete audit)

**Case Studies**:

- INTERACTIVE-MODE-IMPLEMENTATION.md (Achievement 0.3 pattern)
- PROMPT-AUTOMATION-COMPLEXITY-POST-MORTEM.md (why it's hard)

**Code**:

- `LLM/scripts/generation/generate_prompt.py` (1,920 lines, 24 functions)
- `tests/LLM/scripts/generation/` (96 tests across 5 files)

---

## ğŸ¯ Expected Results

**After Completion**:

1. **Self-Documenting Code**

   - Anyone can read and understand
   - Bug fixes are discoverable
   - Architecture is clear
   - Refactoring is safer

2. **Knowledge Preserved**

   - 11 bugs documented in code
   - Design decisions explained
   - Future improvements noted
   - Test coverage referenced

3. **Refactor-Ready**

   - Clear module boundaries
   - Functions well-documented
   - Safe to extract modules
   - Foundation for Priority 2

4. **Quality Metrics**
   - 24/24 functions documented (100%)
   - 11/11 bugs annotated (100%)
   - Module docstring complete
   - Inline comments throughout

---

## ğŸ“ Documentation Best Practices

### For Docstrings

1. **Start with one-line summary** (what it does)
2. **Explain why it exists** (context)
3. **Document bug fixes** (history)
4. **Provide examples** (usage)
5. **Reference tests** (coverage)
6. **Note issues** (known problems)

### For Inline Comments

1. **Explain why, not what** (code shows what)
2. **Reference bug analyses** (detailed context)
3. **Note design decisions** (rationale)
4. **Mark TODOs** (future improvements)

### For Module Docstring

1. **Architecture first** (big picture)
2. **Bug history** (lessons learned)
3. **Design philosophy** (principles)
4. **Future vision** (where we're going)

---

**Status**: âœ… Design Complete, Ready for Execution  
**Next Step**: Create EXECUTION_TASK_PROMPT-GENERATOR-UX-AND-FOUNDATION_12_01.md  
**Estimated Time**: 5-6 hours  
**Confidence**: High (clear documentation plan, all references available)  
**Note**: This is a significant effort - recommend fresh session when ready
